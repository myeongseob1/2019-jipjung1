{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xitplqMNk_Hc",
        "outputId": "ed4f60d2-878d-4056-c438-352dac39a112",
        "colab": {
          "height": 420
        }
      },
      "source": [
        "#@title Introducing Colaboratory { display-mode: \"form\" }\n",
        "#@markdown This 3-minute video gives an overview of the key features of Colaboratory:\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('inN8seMm7UI', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"400\"\n",
              "            src=\"https://www.youtube.com/embed/inN8seMm7UI\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f956e9dda50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "The document you are reading is a  [Jupyter notebook](https://jupyter.org/), hosted in Colaboratory. It is not a static page, but an interactive environment that lets you write and execute code in Python and other languages.\n",
        "\n",
        "For example, here is a **code cell** with a short Python script that computes a value, stores it in a variable, and prints the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJr_9dXGpJ05",
        "outputId": "5626194c-e802-4293-942d-2908885c3c1f",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_day = 24 * 60 * 60\n",
        "seconds_in_a_day"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "To execute the code in the above cell, select it with a click and then either press the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\".\n",
        "\n",
        "All cells modify the same global state, so variables that you define by executing a cell can be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gE-Ez1qtyIA",
        "outputId": "8d2e4259-4682-4e19-b683-7b9087f28820",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "seconds_in_a_week"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "For more information about working with Colaboratory notebooks, see [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "Learn how to make the most of Python, Jupyter, Colaboratory, and related tools with these resources:\n",
        "\n",
        "### Working with Notebooks in Colaboratory\n",
        "- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb) \n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas](/notebooks/mlcc/intro_to_pandas.ipynb)\n",
        "- [Tensorflow concepts](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)\n",
        "- [First steps with TensorFlow](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)\n",
        "- [Intro to neural nets](/notebooks/mlcc/intro_to_neural_nets.ipynb)\n",
        "- [Intro to sparse data and embeddings](/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb)\n",
        "\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-H6Lw1vyNNd"
      },
      "source": [
        "## Machine Learning Examples: Seedbank\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out the [Seedbank](https://research.google.com/seedbank/) project.\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Neural Style Transfer](https://research.google.com/seedbank/seed/neural_style_transfer_with_tfkeras): Use deep learning to transfer style between images.\n",
        "- [EZ NSynth](https://research.google.com/seedbank/seed/ez_nsynth): Synthesize audio with WaveNet auto-encoders.\n",
        "- [Fashion MNIST with Keras and TPUs](https://research.google.com/seedbank/seed/fashion_mnist_with_keras_and_tpus): Classify fashion-related images with deep learning.\n",
        "- [DeepDream](https://research.google.com/seedbank/seed/deepdream): Produce DeepDream images from your own photos.\n",
        "- [Convolutional VAE](https://research.google.com/seedbank/seed/convolutional_vae): Create a generative model of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEUi2WLLtE09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf49114e-0322-4d4d-b4dd-afa5802b084d"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar100\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        " \n",
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate\n",
        " \n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        " \n",
        "#z-score\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        " \n",
        "num_classes = 100\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)\n",
        " \n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        " \n",
        "#training\n",
        "batch_size = 200\n",
        " \n",
        "opt_rms = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=20,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\n",
        "#save to disk\n",
        "model_json = model.to_json()\n",
        "with open('model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights('model.h5') \n",
        " \n",
        "#testing\n",
        "scores = model.evaluate(x_test, y_test, batch_size=200, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               204900    \n",
            "=================================================================\n",
            "Total params: 493,700\n",
            "Trainable params: 492,804\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "250/250 [==============================] - 36s 142ms/step - loss: 4.4226 - acc: 0.1044 - val_loss: 3.8825 - val_acc: 0.1552\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 32s 130ms/step - loss: 3.5445 - acc: 0.2034 - val_loss: 3.3708 - val_acc: 0.2221\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 34s 136ms/step - loss: 3.0717 - acc: 0.2753 - val_loss: 2.9526 - val_acc: 0.2977\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 33s 132ms/step - loss: 2.7954 - acc: 0.3239 - val_loss: 2.9240 - val_acc: 0.3256\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 33s 130ms/step - loss: 2.6333 - acc: 0.3546 - val_loss: 2.6372 - val_acc: 0.3698\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 34s 137ms/step - loss: 2.4997 - acc: 0.3836 - val_loss: 2.4525 - val_acc: 0.4015\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 2.4150 - acc: 0.4042 - val_loss: 2.3190 - val_acc: 0.4277\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 33s 130ms/step - loss: 2.3182 - acc: 0.4191 - val_loss: 2.2126 - val_acc: 0.4456\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 34s 138ms/step - loss: 2.1823 - acc: 0.4419 - val_loss: 2.1428 - val_acc: 0.4612\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 33s 133ms/step - loss: 2.1075 - acc: 0.4592 - val_loss: 2.1201 - val_acc: 0.4719\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 33s 132ms/step - loss: 2.0466 - acc: 0.4729 - val_loss: 2.1145 - val_acc: 0.4743\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 34s 137ms/step - loss: 2.0014 - acc: 0.4846 - val_loss: 2.0347 - val_acc: 0.4848\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 33s 134ms/step - loss: 1.9608 - acc: 0.4918 - val_loss: 2.0989 - val_acc: 0.4875\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 32s 130ms/step - loss: 1.9137 - acc: 0.5039 - val_loss: 1.8891 - val_acc: 0.5186\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 34s 137ms/step - loss: 1.8798 - acc: 0.5127 - val_loss: 1.9547 - val_acc: 0.5088\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 1.8513 - acc: 0.5224 - val_loss: 1.8875 - val_acc: 0.5191\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 1.8195 - acc: 0.5292 - val_loss: 1.9256 - val_acc: 0.5245\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 34s 138ms/step - loss: 1.8039 - acc: 0.5331 - val_loss: 1.8322 - val_acc: 0.5416\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 33s 133ms/step - loss: 1.7789 - acc: 0.5369 - val_loss: 1.8159 - val_acc: 0.5431\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 33s 132ms/step - loss: 1.7604 - acc: 0.5429 - val_loss: 1.9391 - val_acc: 0.5332\n",
            "10000/10000 [==============================] - 1s 109us/step\n",
            "\n",
            "Test result: 53.320 loss: 1.939\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}