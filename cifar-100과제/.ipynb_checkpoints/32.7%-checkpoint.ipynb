{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fCEDCU_qrC0"
   },
   "source": [
    "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
    "\n",
    "<h1>Welcome to Colaboratory!</h1>\n",
    "\n",
    "\n",
    "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
    "\n",
    "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 420
    },
    "colab_type": "code",
    "id": "xitplqMNk_Hc",
    "outputId": "ed4f60d2-878d-4056-c438-352dac39a112"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"400\"\n",
       "            src=\"https://www.youtube.com/embed/inN8seMm7UI\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f956e9dda50>"
      ]
     },
     "execution_count": 0,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Introducing Colaboratory { display-mode: \"form\" }\n",
    "#@markdown This 3-minute video gives an overview of the key features of Colaboratory:\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('inN8seMm7UI', width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJBs_flRovLc"
   },
   "source": [
    "## Getting Started\n",
    "\n",
    "The document you are reading is a  [Jupyter notebook](https://jupyter.org/), hosted in Colaboratory. It is not a static page, but an interactive environment that lets you write and execute code in Python and other languages.\n",
    "\n",
    "For example, here is a **code cell** with a short Python script that computes a value, stores it in a variable, and prints the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 35
    },
    "colab_type": "code",
    "id": "gJr_9dXGpJ05",
    "outputId": "5626194c-e802-4293-942d-2908885c3c1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86400"
      ]
     },
     "execution_count": 0,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fhs6GZ4qFMx"
   },
   "source": [
    "To execute the code in the above cell, select it with a click and then either press the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\".\n",
    "\n",
    "All cells modify the same global state, so variables that you define by executing a cell can be used in other cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "height": 35
    },
    "colab_type": "code",
    "id": "-gE-Ez1qtyIA",
    "outputId": "8d2e4259-4682-4e19-b683-7b9087f28820"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604800"
      ]
     },
     "execution_count": 0,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSrWNr3MuFUS"
   },
   "source": [
    "For more information about working with Colaboratory notebooks, see [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Rh3-Vt9Nev9"
   },
   "source": [
    "## More Resources\n",
    "\n",
    "Learn how to make the most of Python, Jupyter, Colaboratory, and related tools with these resources:\n",
    "\n",
    "### Working with Notebooks in Colaboratory\n",
    "- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
    "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
    "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
    "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
    "- [Interactive forms](/notebooks/forms.ipynb)\n",
    "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
    "\n",
    "### Working with Data\n",
    "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb) \n",
    "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
    "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
    "\n",
    "### Machine Learning Crash Course\n",
    "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
    "- [Intro to Pandas](/notebooks/mlcc/intro_to_pandas.ipynb)\n",
    "- [Tensorflow concepts](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)\n",
    "- [First steps with TensorFlow](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)\n",
    "- [Intro to neural nets](/notebooks/mlcc/intro_to_neural_nets.ipynb)\n",
    "- [Intro to sparse data and embeddings](/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb)\n",
    "\n",
    "### Using Accelerated Hardware\n",
    "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
    "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-H6Lw1vyNNd"
   },
   "source": [
    "## Machine Learning Examples: Seedbank\n",
    "\n",
    "To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out the [Seedbank](https://research.google.com/seedbank/) project.\n",
    "\n",
    "A few featured examples:\n",
    "\n",
    "- [Neural Style Transfer](https://research.google.com/seedbank/seed/neural_style_transfer_with_tfkeras): Use deep learning to transfer style between images.\n",
    "- [EZ NSynth](https://research.google.com/seedbank/seed/ez_nsynth): Synthesize audio with WaveNet auto-encoders.\n",
    "- [Fashion MNIST with Keras and TPUs](https://research.google.com/seedbank/seed/fashion_mnist_with_keras_and_tpus): Classify fashion-related images with deep learning.\n",
    "- [DeepDream](https://research.google.com/seedbank/seed/deepdream): Produce DeepDream images from your own photos.\n",
    "- [Convolutional VAE](https://research.google.com/seedbank/seed/convolutional_vae): Create a generative model of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8mVG88wxWggi",
    "outputId": "33f38a8f-ed97-44b7-c12c-bf152a028326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/120\n",
      "47500/47500 [==============================] - 19s 406us/step - loss: 4.1113 - acc: 0.0833 - val_loss: 3.7455 - val_acc: 0.1436\n",
      "Epoch 2/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 3.7668 - acc: 0.1339 - val_loss: 3.6205 - val_acc: 0.1604\n",
      "Epoch 3/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 3.6401 - acc: 0.1548 - val_loss: 3.5044 - val_acc: 0.1864\n",
      "Epoch 4/120\n",
      "47500/47500 [==============================] - 15s 326us/step - loss: 3.5381 - acc: 0.1716 - val_loss: 3.4408 - val_acc: 0.1988\n",
      "Epoch 5/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 3.4588 - acc: 0.1833 - val_loss: 3.4031 - val_acc: 0.1964\n",
      "Epoch 6/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 3.3824 - acc: 0.1955 - val_loss: 3.3465 - val_acc: 0.2124\n",
      "Epoch 7/120\n",
      "47500/47500 [==============================] - 16s 326us/step - loss: 3.3285 - acc: 0.2069 - val_loss: 3.2889 - val_acc: 0.2184\n",
      "Epoch 8/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 3.2599 - acc: 0.2170 - val_loss: 3.2852 - val_acc: 0.2280\n",
      "Epoch 9/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 3.2106 - acc: 0.2268 - val_loss: 3.2219 - val_acc: 0.2340\n",
      "Epoch 10/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 3.1548 - acc: 0.2363 - val_loss: 3.1717 - val_acc: 0.2424\n",
      "Epoch 11/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 3.1123 - acc: 0.2440 - val_loss: 3.1480 - val_acc: 0.2384\n",
      "Epoch 12/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 3.0603 - acc: 0.2529 - val_loss: 3.1897 - val_acc: 0.2380\n",
      "Epoch 13/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 3.0169 - acc: 0.2584 - val_loss: 3.1263 - val_acc: 0.2432\n",
      "Epoch 14/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 2.9639 - acc: 0.2695 - val_loss: 3.1220 - val_acc: 0.2512\n",
      "Epoch 15/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 2.9151 - acc: 0.2775 - val_loss: 3.0939 - val_acc: 0.2560\n",
      "Epoch 16/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 2.8731 - acc: 0.2877 - val_loss: 3.0778 - val_acc: 0.2656\n",
      "Epoch 17/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 2.8345 - acc: 0.2925 - val_loss: 3.0785 - val_acc: 0.2644\n",
      "Epoch 18/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 2.7935 - acc: 0.3020 - val_loss: 3.0281 - val_acc: 0.2692\n",
      "Epoch 19/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 2.7544 - acc: 0.3061 - val_loss: 3.0335 - val_acc: 0.2660\n",
      "Epoch 20/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 2.7025 - acc: 0.3192 - val_loss: 3.0373 - val_acc: 0.2760\n",
      "Epoch 21/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 2.6629 - acc: 0.3290 - val_loss: 3.0125 - val_acc: 0.2736\n",
      "Epoch 22/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 2.6171 - acc: 0.3368 - val_loss: 3.0217 - val_acc: 0.2696\n",
      "Epoch 23/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 2.5888 - acc: 0.3412 - val_loss: 2.9911 - val_acc: 0.2812\n",
      "Epoch 24/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 2.5481 - acc: 0.3480 - val_loss: 2.9747 - val_acc: 0.2876\n",
      "Epoch 25/120\n",
      "47500/47500 [==============================] - 16s 327us/step - loss: 2.5008 - acc: 0.3605 - val_loss: 2.9835 - val_acc: 0.2748\n",
      "Epoch 26/120\n",
      "47500/47500 [==============================] - 15s 320us/step - loss: 2.4626 - acc: 0.3664 - val_loss: 2.9941 - val_acc: 0.2840\n",
      "Epoch 27/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 2.4244 - acc: 0.3761 - val_loss: 2.9872 - val_acc: 0.2788\n",
      "Epoch 28/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 2.3826 - acc: 0.3847 - val_loss: 2.9833 - val_acc: 0.2812\n",
      "Epoch 29/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 2.3499 - acc: 0.3907 - val_loss: 3.0014 - val_acc: 0.2788\n",
      "Epoch 30/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 2.3140 - acc: 0.3965 - val_loss: 2.9791 - val_acc: 0.2936\n",
      "Epoch 31/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 2.2672 - acc: 0.4055 - val_loss: 2.9675 - val_acc: 0.2848\n",
      "Epoch 32/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 2.2325 - acc: 0.4158 - val_loss: 2.9541 - val_acc: 0.2880\n",
      "Epoch 33/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 2.2013 - acc: 0.4235 - val_loss: 2.9587 - val_acc: 0.2908\n",
      "Epoch 34/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 2.1548 - acc: 0.4326 - val_loss: 2.9675 - val_acc: 0.2920\n",
      "Epoch 35/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 2.1253 - acc: 0.4394 - val_loss: 2.9422 - val_acc: 0.2952\n",
      "Epoch 36/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 2.0870 - acc: 0.4498 - val_loss: 2.9796 - val_acc: 0.2988\n",
      "Epoch 37/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 2.0485 - acc: 0.4555 - val_loss: 2.9733 - val_acc: 0.2836\n",
      "Epoch 38/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 2.0165 - acc: 0.4647 - val_loss: 2.9662 - val_acc: 0.2996\n",
      "Epoch 39/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 1.9701 - acc: 0.4762 - val_loss: 2.9730 - val_acc: 0.2972\n",
      "Epoch 40/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 1.9382 - acc: 0.4845 - val_loss: 2.9356 - val_acc: 0.3004\n",
      "Epoch 41/120\n",
      "47500/47500 [==============================] - 15s 320us/step - loss: 1.9108 - acc: 0.4901 - val_loss: 2.9518 - val_acc: 0.3052\n",
      "Epoch 42/120\n",
      "47500/47500 [==============================] - 15s 320us/step - loss: 1.8726 - acc: 0.4972 - val_loss: 2.9492 - val_acc: 0.3060\n",
      "Epoch 43/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 1.8338 - acc: 0.5066 - val_loss: 2.9679 - val_acc: 0.3004\n",
      "Epoch 44/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 1.8042 - acc: 0.5159 - val_loss: 2.9673 - val_acc: 0.3048\n",
      "Epoch 45/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 1.7683 - acc: 0.5241 - val_loss: 2.9629 - val_acc: 0.3036\n",
      "Epoch 46/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 1.7286 - acc: 0.5319 - val_loss: 2.9764 - val_acc: 0.3072\n",
      "Epoch 47/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 1.7025 - acc: 0.5382 - val_loss: 2.9622 - val_acc: 0.3044\n",
      "Epoch 48/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 1.6605 - acc: 0.5493 - val_loss: 2.9869 - val_acc: 0.3028\n",
      "Epoch 49/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 1.6287 - acc: 0.5561 - val_loss: 2.9786 - val_acc: 0.3028\n",
      "Epoch 50/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 1.5981 - acc: 0.5648 - val_loss: 2.9768 - val_acc: 0.3116\n",
      "Epoch 51/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 1.5580 - acc: 0.5765 - val_loss: 3.0073 - val_acc: 0.3060\n",
      "Epoch 52/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 1.5362 - acc: 0.5792 - val_loss: 2.9960 - val_acc: 0.3100\n",
      "Epoch 53/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 1.4984 - acc: 0.5892 - val_loss: 3.0087 - val_acc: 0.3080\n",
      "Epoch 54/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 1.4623 - acc: 0.6005 - val_loss: 2.9941 - val_acc: 0.3160\n",
      "Epoch 55/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 1.4338 - acc: 0.6050 - val_loss: 3.0426 - val_acc: 0.3156\n",
      "Epoch 56/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 1.4038 - acc: 0.6161 - val_loss: 3.0227 - val_acc: 0.3080\n",
      "Epoch 57/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 1.3755 - acc: 0.6219 - val_loss: 3.0133 - val_acc: 0.3176\n",
      "Epoch 58/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 1.3390 - acc: 0.6318 - val_loss: 3.0115 - val_acc: 0.3152\n",
      "Epoch 59/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 1.3086 - acc: 0.6415 - val_loss: 3.0304 - val_acc: 0.3160\n",
      "Epoch 60/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 1.2803 - acc: 0.6463 - val_loss: 3.0307 - val_acc: 0.3160\n",
      "Epoch 61/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 1.2474 - acc: 0.6560 - val_loss: 3.0668 - val_acc: 0.3172\n",
      "Epoch 62/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 1.2260 - acc: 0.6609 - val_loss: 3.0813 - val_acc: 0.3108\n",
      "Epoch 63/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 1.1848 - acc: 0.6739 - val_loss: 3.0753 - val_acc: 0.3168\n",
      "Epoch 64/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 1.1630 - acc: 0.6782 - val_loss: 3.1002 - val_acc: 0.3140\n",
      "Epoch 65/120\n",
      "47500/47500 [==============================] - 15s 326us/step - loss: 1.1313 - acc: 0.6857 - val_loss: 3.0954 - val_acc: 0.3204\n",
      "Epoch 66/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 1.1028 - acc: 0.6935 - val_loss: 3.1049 - val_acc: 0.3272\n",
      "Epoch 67/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 1.0742 - acc: 0.7021 - val_loss: 3.1204 - val_acc: 0.3148\n",
      "Epoch 68/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 1.0535 - acc: 0.7073 - val_loss: 3.1271 - val_acc: 0.3176\n",
      "Epoch 69/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 1.0260 - acc: 0.7164 - val_loss: 3.1480 - val_acc: 0.3068\n",
      "Epoch 70/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 0.9985 - acc: 0.7237 - val_loss: 3.1514 - val_acc: 0.3212\n",
      "Epoch 71/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 0.9837 - acc: 0.7258 - val_loss: 3.1490 - val_acc: 0.3128\n",
      "Epoch 72/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.9624 - acc: 0.7322 - val_loss: 3.1664 - val_acc: 0.3192\n",
      "Epoch 73/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 0.9173 - acc: 0.7433 - val_loss: 3.1559 - val_acc: 0.3236\n",
      "Epoch 74/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.9005 - acc: 0.7493 - val_loss: 3.1796 - val_acc: 0.3200\n",
      "Epoch 75/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 0.8782 - acc: 0.7581 - val_loss: 3.1892 - val_acc: 0.3240\n",
      "Epoch 76/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 0.8517 - acc: 0.7653 - val_loss: 3.2028 - val_acc: 0.3192\n",
      "Epoch 77/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 0.8314 - acc: 0.7722 - val_loss: 3.2314 - val_acc: 0.3248\n",
      "Epoch 78/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 0.8127 - acc: 0.7746 - val_loss: 3.2349 - val_acc: 0.3212\n",
      "Epoch 79/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 0.7901 - acc: 0.7815 - val_loss: 3.2584 - val_acc: 0.3200\n",
      "Epoch 80/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 0.7606 - acc: 0.7907 - val_loss: 3.2828 - val_acc: 0.3184\n",
      "Epoch 81/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.7458 - acc: 0.7939 - val_loss: 3.2674 - val_acc: 0.3212\n",
      "Epoch 82/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 0.7257 - acc: 0.8010 - val_loss: 3.2959 - val_acc: 0.3152\n",
      "Epoch 83/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 0.7076 - acc: 0.8033 - val_loss: 3.2896 - val_acc: 0.3188\n",
      "Epoch 84/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 0.6904 - acc: 0.8091 - val_loss: 3.3178 - val_acc: 0.3116\n",
      "Epoch 85/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 0.6684 - acc: 0.8145 - val_loss: 3.3111 - val_acc: 0.3220\n",
      "Epoch 86/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 0.6419 - acc: 0.8231 - val_loss: 3.3402 - val_acc: 0.3268\n",
      "Epoch 87/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.6331 - acc: 0.8254 - val_loss: 3.3608 - val_acc: 0.3196\n",
      "Epoch 88/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.6112 - acc: 0.8332 - val_loss: 3.3665 - val_acc: 0.3152\n",
      "Epoch 89/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.5962 - acc: 0.8357 - val_loss: 3.3635 - val_acc: 0.3168\n",
      "Epoch 90/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 0.5772 - acc: 0.8443 - val_loss: 3.3912 - val_acc: 0.3208\n",
      "Epoch 91/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.5723 - acc: 0.8418 - val_loss: 3.4071 - val_acc: 0.3200\n",
      "Epoch 92/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 0.5541 - acc: 0.8459 - val_loss: 3.4079 - val_acc: 0.3184\n",
      "Epoch 93/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 0.5387 - acc: 0.8512 - val_loss: 3.4363 - val_acc: 0.3196\n",
      "Epoch 94/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 0.5298 - acc: 0.8559 - val_loss: 3.4454 - val_acc: 0.3176\n",
      "Epoch 95/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.5073 - acc: 0.8599 - val_loss: 3.4589 - val_acc: 0.3148\n",
      "Epoch 96/120\n",
      "47500/47500 [==============================] - 15s 320us/step - loss: 0.4916 - acc: 0.8655 - val_loss: 3.4718 - val_acc: 0.3140\n",
      "Epoch 97/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 0.4847 - acc: 0.8676 - val_loss: 3.4773 - val_acc: 0.3140\n",
      "Epoch 98/120\n",
      "47500/47500 [==============================] - 15s 321us/step - loss: 0.4694 - acc: 0.8713 - val_loss: 3.4668 - val_acc: 0.3208\n",
      "Epoch 99/120\n",
      "47500/47500 [==============================] - 15s 324us/step - loss: 0.4591 - acc: 0.8748 - val_loss: 3.5110 - val_acc: 0.3200\n",
      "Epoch 100/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.4504 - acc: 0.8766 - val_loss: 3.5304 - val_acc: 0.3216\n",
      "Epoch 101/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.4343 - acc: 0.8823 - val_loss: 3.5341 - val_acc: 0.3188\n",
      "Epoch 102/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 0.4241 - acc: 0.8853 - val_loss: 3.5325 - val_acc: 0.3236\n",
      "Epoch 103/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 0.4114 - acc: 0.8881 - val_loss: 3.5509 - val_acc: 0.3220\n",
      "Epoch 104/120\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 0.3964 - acc: 0.8925 - val_loss: 3.5671 - val_acc: 0.3224\n",
      "Epoch 105/120\n",
      "47500/47500 [==============================] - 16s 329us/step - loss: 0.3903 - acc: 0.8947 - val_loss: 3.6060 - val_acc: 0.3136\n",
      "Epoch 106/120\n",
      "47500/47500 [==============================] - 16s 333us/step - loss: 0.3841 - acc: 0.8949 - val_loss: 3.6103 - val_acc: 0.3176\n",
      "Epoch 107/120\n",
      "47500/47500 [==============================] - 16s 337us/step - loss: 0.3783 - acc: 0.8982 - val_loss: 3.6223 - val_acc: 0.3100\n",
      "Epoch 108/120\n",
      "47500/47500 [==============================] - 16s 335us/step - loss: 0.3607 - acc: 0.9034 - val_loss: 3.6265 - val_acc: 0.3208\n",
      "Epoch 109/120\n",
      "47500/47500 [==============================] - 16s 335us/step - loss: 0.3621 - acc: 0.9021 - val_loss: 3.6720 - val_acc: 0.3172\n",
      "Epoch 110/120\n",
      "47500/47500 [==============================] - 16s 335us/step - loss: 0.3498 - acc: 0.9032 - val_loss: 3.6548 - val_acc: 0.3232\n",
      "Epoch 111/120\n",
      "47500/47500 [==============================] - 16s 329us/step - loss: 0.3430 - acc: 0.9053 - val_loss: 3.6884 - val_acc: 0.3152\n",
      "Epoch 112/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 0.3336 - acc: 0.9107 - val_loss: 3.7043 - val_acc: 0.3236\n",
      "Epoch 113/120\n",
      "47500/47500 [==============================] - 16s 327us/step - loss: 0.3230 - acc: 0.9131 - val_loss: 3.6893 - val_acc: 0.3236\n",
      "Epoch 114/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 0.3108 - acc: 0.9177 - val_loss: 3.7260 - val_acc: 0.3148\n",
      "Epoch 115/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.3109 - acc: 0.9165 - val_loss: 3.7483 - val_acc: 0.3164\n",
      "Epoch 116/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.3017 - acc: 0.9180 - val_loss: 3.7497 - val_acc: 0.3188\n",
      "Epoch 117/120\n",
      "47500/47500 [==============================] - 15s 322us/step - loss: 0.2926 - acc: 0.9215 - val_loss: 3.7288 - val_acc: 0.3108\n",
      "Epoch 118/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.2854 - acc: 0.9239 - val_loss: 3.7780 - val_acc: 0.3160\n",
      "Epoch 119/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.2779 - acc: 0.9251 - val_loss: 3.7869 - val_acc: 0.3196\n",
      "Epoch 120/120\n",
      "47500/47500 [==============================] - 15s 323us/step - loss: 0.2835 - acc: 0.9233 - val_loss: 3.7995 - val_acc: 0.3264\n",
      "10000/10000 [==============================] - 1s 63us/step\n",
      "Test Loss and Accuracy -> [3.7509081101417543, 0.32700000271201135]\n"
     ]
    }
   ],
   "source": [
    "# DNN_CIFAR-10 / MNIST보다 복잡한 데이터의 처리(R,G,B)\n",
    "import numpy as np\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "from keras import layers, models\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class DNN(models.Sequential):\n",
    "    def __init__(self, Nin, Nh_l, Pd_l, Nout):\n",
    "        super().__init__()\n",
    "        # 첫 번째 은닉\n",
    "        self.add(layers.Dense(Nh_l[0], activation='elu',input_shape=(Nin,), name='Hidden-1'))\n",
    "        # Dropout 확률을 정한다.\n",
    "        # Dropout : 랜덤으로 몇개의 노드를 비활성화 한다.(오버피팅 방지)\n",
    "        self.add(layers.Dropout(Pd_l[0]))\n",
    "        self.add(layers.Dense(Nh_l[1], activation='elu', name='Hidden-2'))\n",
    "        self.add(layers.Dropout(Pd_l[1]))\n",
    "        self.add(layers.Dense(Nh_l[2], activation='elu', name='Hidden-3'))\n",
    "        self.add(layers.Dropout(Pd_l[2]))\n",
    "        self.add(layers.Dense(Nh_l[2], activation='elu', name='Hidden-4'))\n",
    "        self.add(layers.Dropout(Pd_l[2]))\n",
    "        self.add(layers.Dense(Nh_l[4], activation='tanh', name='Hidden-6'))\n",
    "        self.add(layers.Dropout(Pd_l[4]))\n",
    "        self.add(layers.Dense(Nout, activation='softmax'))\n",
    "        self.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.00005, beta_1=0.9, beta_2=0.999), metrics=['accuracy'])\n",
    "\n",
    "# 데이터 정리\n",
    "def Data_func():\n",
    "    (X_train, y_train), (X_test, y_test) = datasets.cifar100.load_data()\n",
    " \n",
    "    # 0~9 사이의 정수값을 10개의 원소를 가지는 벡터로 변환\n",
    "    # 1 -> 0100000000, 2 -> 0010000000, 9 -> 0000000001\n",
    "    Y_train = np_utils.to_categorical(y_train)\n",
    "    Y_test = np_utils.to_categorical(y_test)\n",
    " \n",
    "    L, W, H, C = X_train.shape\n",
    "    X_train = X_train.reshape(-1, W * H * C)\n",
    "    X_test = X_test.reshape(-1, W * H * C)\n",
    " \n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    " \n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# 모델 테스팅\n",
    "def main():\n",
    "    Nh_l = [2000, 1000, 2000,1000,1500]\n",
    "    Pd_l = [0.1, 0.2, 0.2,0.2,0.2]\n",
    "    number_of_class = 100\n",
    "    Nout = number_of_class\n",
    " \n",
    "    (X_train, Y_train), (X_test, Y_test) = Data_func()\n",
    "    model = DNN(X_train.shape[1], Nh_l, Pd_l, Nout)\n",
    "    history = model.fit(X_train, Y_train, epochs=120, batch_size=100, validation_split=0.05)\n",
    " \n",
    "    performace_test = model.evaluate(X_test, Y_test, batch_size=100)\n",
    "    print('Test Loss and Accuracy ->', performace_test)\n",
    " \n",
    "    plt.show()\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnLDZ6rq3edg"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Welcome To Colaboratory",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
